{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script splits the full training data into training and feedback sets to demonstrate the improvements achievable with the feedback set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11752\n",
      "2938\n"
     ]
    }
   ],
   "source": [
    "part_train, part_feedback = train_test_split(full_train, test_size=feedback_perc)\n",
    "print(len(part_train))\n",
    "print(len(part_feedback))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_COMPONENTS = ('multi_sql','keyword','col','op','agg','root_tem','des_asc','having','andor')\n",
    "feedback_perc = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Component: multi_sql\n",
      "Training Data Size: 6853\n",
      "Feedback Data Size: 1714\n",
      "\n",
      "Component: keyword\n",
      "Training Data Size: 6437\n",
      "Feedback Data Size: 1610\n",
      "\n",
      "Component: col\n",
      "Training Data Size: 12685\n",
      "Feedback Data Size: 3172\n",
      "\n",
      "Component: op\n",
      "Training Data Size: 3994\n",
      "Feedback Data Size: 999\n",
      "\n",
      "Component: agg\n",
      "Training Data Size: 11752\n",
      "Feedback Data Size: 2938\n",
      "\n",
      "Component: root_tem\n",
      "Training Data Size: 4126\n",
      "Feedback Data Size: 1032\n",
      "\n",
      "Component: des_asc\n",
      "Training Data Size: 1296\n",
      "Feedback Data Size: 324\n",
      "\n",
      "Component: having\n",
      "Training Data Size: 1429\n",
      "Feedback Data Size: 358\n",
      "\n",
      "Component: andor\n",
      "Training Data Size: 567\n",
      "Feedback Data Size: 142\n"
     ]
    }
   ],
   "source": [
    "for train_comp in TRAIN_COMPONENTS:\n",
    "    print(\"\\nComponent: {}\".format(train_comp))\n",
    "    \n",
    "    # open the full training data json file\n",
    "    with open(\"./generated_data/full_train_{}_dataset.json\".format(train_comp)) as json_file:\n",
    "        full_train = json.load(json_file)\n",
    "        \n",
    "    part_train, part_feedback = train_test_split(full_train, test_size=feedback_perc)\n",
    "    print(\"Training Data Size: {}\".format(len(part_train)))\n",
    "    print(\"Feedback Data Size: {}\".format(len(part_feedback)))\n",
    "    \n",
    "    # Save the files\n",
    "    with open(\"./generated_data/part_train_{}_dataset.json\".format(train_comp), 'w') as outfile:  \n",
    "        json.dump(part_train, outfile)\n",
    "    with open(\"./generated_data/part_feedback_{}_dataset.json\".format(train_comp), 'w') as outfile:  \n",
    "        json.dump(part_feedback, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
